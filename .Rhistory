#select relevant columns
TC <- TC %>% select(transect, date, Animal, Count)
#split date to month, day, year
TC <- separate(data = TC, col = date, into = c("month", "day", "year"), sep = "/")
#set columns to numeric values
TC$year <- as.numeric(TC$year)
TC$month <- as.numeric(TC$month)
TC$day <- as.numeric(TC$day)
TC$Count <- as.numeric(TC$Count)
#determine 1st or 2nd replicate of the month
TC <- TC %>% group_by(Animal, transect, month, year) %>%
mutate(min_day = min(day),
max_day = max(day),
n_day = n_distinct(day)) %>%
filter(!(n_day == 3 & max_day == day)) %>%
mutate(k = ifelse(n_day == 1 & day < 16, 1,
ifelse(n_day == 2 & day == min_day, 1,
ifelse(n_day == 3 & day == min_day, 1,0)))) %>%
select(transect, month, day, year, Animal, Count, k)
#function to generate replicates
reps <- function(month, day, year, k){
yr <- year - 2011
reps <- ((month * 2) - k) + yr * 24 - 24
return(reps)
}
#generate replicate, site, and species IDs
TC <- TC %>% mutate(reps = reps(month, day, year, k),
site = as.numeric(transect),
spec = as.numeric(Animal))
#number of sites
nsites <- NULL
nsites[1] <- max(DS$site) #distance sampling
nsites[2] <- max(TC$site) #transect counts
#adjust transect counts site ID
TC <- TC %>% mutate(site = site + nsites[1])
#number of replicates
nreps <- NULL
nreps[1] <- max(DS$reps) #distance sampling
nreps[2] <- max(TC$reps) #transect counts
#start and end replicate for each site
nstart <- c(rep(1,nsites[1]), rep(nreps[1]+1,nsites[2]))
nend <- c(rep(nreps[1],nsites[1]), rep(nreps[1]+nreps[2],nsites[2]))
#adjust transect counts replicate ID
TC <- TC %>% mutate(reps = reps + nreps[1])
#number of species
nspec <- 14
#observation array
y <- array(NA, dim = c(sum(nreps), sum(nsites), nspec))
#set distance sampling counts to 0 as sampling always occuried
y[1:nreps[1],1:nsites[1],] <- 0
for(i in 1:dim(DS)[1]){
if(DS$spec[i] > 14){
next
}
y[DS$reps[i],DS$site[i],DS$spec[i]] <- as.numeric(DS$Count[i]) + y[DS$reps[i],DS$site[i],DS$spec[i]]
}
for(i in 1:dim(TC)[1]){
if(TC$spec[i] > 14){
next
}
y[TC$reps[i],TC$site[i],TC$spec[i]] <- as.numeric(TC$Count[i])
}
#Width of distance classes
v <- 25 #meters
#Transect half-width
B <- 1000 #meters
#Distance class midpoint ID
mdpt <- seq(v/2, B, v)
#area of transects (m^2)
area <- as.numeric(c(st_length(DSshape)*1000*2, st_length(TCshape)*200*2))
#set baseline unit as 1 km^2
offset <- area/1E6
Data <- list(y, dclass, v, B, mdpt, nG, nobs,
nreps, nstart, nend, nsites, nspec, DS$reps, DS$site, DS$spec,
offset)
heads <- c("y", "dclass", "v", "B", "mdpt", "nG", "nobs",
"nreps", "nstart", "nend", "nsites", "nspec", "reps", "site", "spec")
Data <- setNames(Data, nm = heads)
setwd("C:/Users/cblom/Documents/ZQE_Lab/HerbData") #CB
library(tidyverse)
# library(raster) I don't (anymore) add the raster library because it interfers with tidyverse functions. Instead I call raster functions using raster::
library(sf)
library(dplyr)
library(sp)
DS <- read.csv("~/ZQE_Lab/HerbData/Herbivore Utilization Complete.csv", header=TRUE) #CB
DS$Animal <- as.factor(DS$Animal)
DS <- filter(DS,
Animal == "Buffalo" |
Animal == "Eland" |
Animal == "Elephant" |
Animal == "Giraffe" |
Animal == "Grants" |
Animal == "Hartebeest" |
Animal == "Hippo" |
Animal == "Impala" |
Animal == "Thomsons" |
Animal == "Topi" |
Animal == "Warthog" |
Animal == "Waterbuck" |
Animal == "Wildebeest" |
Animal == "Zebra" |
Animal == "Cattle" |
Animal == "Shoat" |
Animal == "Lion" |
Animal == "Hyena" |
Animal == "BlackBackedJackal") %>% droplevels()
DS$Animal <- factor(DS$Animal,
levels = c("Buffalo", "Eland", "Elephant",
"Giraffe", "Grants", "Hartebeest",
"Hippo", "Impala", "Thomsons",
"Topi", "Warthog", "Waterbuck",
"Wildebeest","Zebra", "Cattle",
"Shoat", "Lion", "Hyena", "BlackBackedJackal"))
#Remove incomplete obs
DS <- DS[-which(is.na(DS$Count)|DS$Count<1),]
#read in DS data
DSshape <- st_read(dsn = "./Shapefiles/DS", layer = "DS_10kmpersite") #CB
#read in data as an sf object
DS <- st_as_sf(DS, coords = c("AdjEasting", "AdjNorthing"), crs = st_crs(DSshape))
#create distance matrix
ds_matrix <- st_distance(DS, DSshape)
#assign transect to each observation
DS$site <- apply(ds_matrix, 1, which.min)
#add corrected distances
DS$dst <- apply(ds_matrix, 1, min)
DS <- DS %>% filter(dst <= 1000)
#Number of observations for distance sampling
nobs <- NULL
nobs[1] <- dim(DS)[1]
#ID for distance class
di <- seq(0,1000,25)
#Distance class
dclass <- rep(NA, nobs[1])
#Number of distance classes
nG <- length(di) - 1
#Minimum distance to assigned transect
dst <- DS$dst
for(i in 1:nobs[1]){
for(k in 1:nG){
if(di[k] < dst[i] && dst[i] <= di[k+1]) #why the k+1 argument?
dclass[i] <- k
}
}
DS$dclass <- dclass
#Replicate
DS$reps[DS$Territory == "North"] <- filter(DS,Territory=="North")%>%group_by(Year, Month)%>%group_indices()
DS$reps[DS$Territory == "South"] <- filter(DS,Territory=="South")%>%group_by(Year, Month)%>%group_indices()
DS$reps[DS$Territory == "West"] <- filter(DS,Territory=="West")%>%group_by(Year, Month)%>%group_indices()
#Filter out unnecessary data
DS <- DS %>% select(Animal, site, reps, Count, dclass)
DS$spec <- as.numeric(DS$Animal)
#read in TC data
TC <- read.csv("~/ZQE_Lab/HerbData/tblPreyCensus_2012to2014.csv", header=TRUE) #CB
#read in transect count shapefiles
TCshape <- st_read(dsn = "./Shapefiles/Transects", layer = "Transects")
#reshape TC to long format
TC <- reshape2::melt(TC, id=colnames(TC)[1:8])
#rename columns
TC <- TC %>% rename("Animal" = "variable", "Count" = "value")
#filter species
TC <- filter(TC,
Animal == "buffalo" |
Animal == "eland" |
Animal == "elephant" |
Animal == "giraffe" |
Animal == "grants" |
Animal == "hartebeest" |
Animal == "hippo" |
Animal == "impala" |
Animal == "thomsons" |
Animal == "topi" |
Animal == "warthog" |
Animal == "waterbuck" |
Animal == "wildebeest" |
Animal == "zebra" |
Animal == "cow" |
Animal == "shoat" |
Animal == "lion" |
Animal == "spotted_hyena" |
Animal == "bb_jackal") %>% droplevels()
#set transects to factor
TC$transect <- as.factor(TC$transect)
#filter transects
TC <- filter(TC,
transect == "WLOW"|
transect == "WHIGH"|
transect == "W3"|
transect == "North"|
transect == "S1"|
transect == "S2"|
transect == "RSP"|
transect == "SST"|
transect == "HZT") %>% droplevels()
#select relevant columns
TC <- TC %>% select(transect, date, Animal, Count)
#split date to month, day, year
TC <- separate(data = TC, col = date, into = c("month", "day", "year"), sep = "/")
#set columns to numeric values
TC$year <- as.numeric(TC$year)
TC$month <- as.numeric(TC$month)
TC$day <- as.numeric(TC$day)
TC$Count <- as.numeric(TC$Count)
#determine 1st or 2nd replicate of the month
TC <- TC %>% group_by(Animal, transect, month, year) %>%
mutate(min_day = min(day),
max_day = max(day),
n_day = n_distinct(day)) %>%
filter(!(n_day == 3 & max_day == day)) %>%
mutate(k = ifelse(n_day == 1 & day < 16, 1,
ifelse(n_day == 2 & day == min_day, 1,
ifelse(n_day == 3 & day == min_day, 1,0)))) %>%
select(transect, month, day, year, Animal, Count, k)
#function to generate replicates
reps <- function(month, day, year, k){
yr <- year - 2011
reps <- ((month * 2) - k) + yr * 24 - 24
return(reps)
}
#generate replicate, site, and species IDs
TC <- TC %>% mutate(reps = reps(month, day, year, k),
site = as.numeric(transect),
spec = as.numeric(Animal))
#number of sites
nsites <- NULL
nsites[1] <- max(DS$site) #distance sampling
nsites[2] <- max(TC$site) #transect counts
#adjust transect counts site ID
TC <- TC %>% mutate(site = site + nsites[1])
#number of replicates
nreps <- NULL
nreps[1] <- max(DS$reps) #distance sampling
nreps[2] <- max(TC$reps) #transect counts
#start and end replicate for each site
nstart <- c(rep(1,nsites[1]), rep(nreps[1]+1,nsites[2]))
nend <- c(rep(nreps[1],nsites[1]), rep(nreps[1]+nreps[2],nsites[2]))
#adjust transect counts replicate ID
TC <- TC %>% mutate(reps = reps + nreps[1])
#number of species
nspec <- 14
#observation array
y <- array(NA, dim = c(sum(nreps), sum(nsites), nspec))
#set distance sampling counts to 0 as sampling always occuried
y[1:nreps[1],1:nsites[1],] <- 0
for(i in 1:dim(DS)[1]){
if(DS$spec[i] > 14){
next
}
y[DS$reps[i],DS$site[i],DS$spec[i]] <- as.numeric(DS$Count[i]) + y[DS$reps[i],DS$site[i],DS$spec[i]]
}
for(i in 1:dim(TC)[1]){
if(TC$spec[i] > 14){
next
}
y[TC$reps[i],TC$site[i],TC$spec[i]] <- as.numeric(TC$Count[i])
}
#Width of distance classes
v <- 25 #meters
#Transect half-width
B <- 1000 #meters
#Distance class midpoint ID
mdpt <- seq(v/2, B, v)
#area of transects (m^2)
area <- as.numeric(c(st_length(DSshape)*1000*2, st_length(TCshape)*200*2))
#set baseline unit as 1 km^2
offset <- area/1E6
Data <- list(y, dclass, v, B, mdpt, nG, nobs,
nreps, nstart, nend, nsites, nspec, DS$reps, DS$site, DS$spec,
offset)
heads <- c("y", "dclass", "v", "B", "mdpt", "nG", "nobs",
"nreps", "nstart", "nend", "nsites", "nspec", "reps", "site", "spec")
Data <- setNames(Data, nm = heads)
save(Data, file = "./DataFormatting/FormattedData.Rdata")
getwd()
#save(Data, file = "./DataFormatting/FormattedData.Rdata")
save(Data, file = "./FormattedData.Rdata")
library(nimble)
library(coda)
getwd(0)
getwd()
cd(~
)
setwd(~)
setwd(~/)
file.choose()
setwd(~)
#load(file = "./DataFormatting/FormattedData.Rdata")
load(file = "~/Documents/ZQE_lab/HerbData/FormattedData.Rdata")
setwd("~")
getwd()
#load(file = "./DataFormatting/FormattedData.Rdata")
load(file = "~/ZQE_lab/HerbData/FormattedData.Rdata")
model.code <- nimbleCode({
#--------#
#-PRIORS-#
#--------#
#Gamma0
mu_s ~ dunif(0, 8)            #Mean
tau_s <- 1/(sig_s * sig_s)    #Precision
sig_s ~ dunif(0, 8)           #Variance
#Alpha0
mu_a0 ~ dnorm(0, 0.1)        #Mean
tau_a0 ~ dgamma(0.1, 0.1)     #Precision
sig_a0 <- 1/sqrt(tau_a0)      #Variance
#Overdispersion
r.N ~ dunif(0,10)            #Number of groups
for(s in 1:nspec){
#Psi
tau_p[s] ~ dgamma(0.1, 0.1)  #Precision
sig_p[s] <- 1/sqrt(tau_p[s]) #Variance
#Sigma
gamma0[s] ~ dnorm(mu_s, tau_s)  #Intercept parameter
#Expected Number of Groups
alpha0[s] ~ dnorm(mu_a0, tau_a0)    #Intercept parameter
#------------#
#-LIKELIHOOD-#
#------------#
#-------------------#
#-Distance sampling-#
#-------------------#
for(j in 1:nsites[1]){
psi[j,s] ~ dnorm(0, tau_p[s])       #Transect effect parameter
#Scale parameter
sigma[j,s] <- exp(gamma0[s])
#Construct cell probabilities for nG cells using numerical integration
#Sum of the area (rectangles) under the detection function
for(k in 1:nG){
#Half normal detection function at midpt (length of rectangle)
g[k,j,s] <- exp(-mdpt[k]*mdpt[k]/(2*sigma[j,s]*sigma[j,s]))
#Detection probability for each distance class k (area of each rectangle)
f[k,j,s] <- g[k,j,s] * v/B
#Conditional detection probability (scale to 1)
fc[k,j,s] <- f[k,j,s]/pcap[j,s]
}#end k loop
#Detection probability at each transect (sum of rectangles)
pcap[j,s] <- sum(f[1:nG,j,s])
for(t in nstart[j]:nend[j]){
#Observed population @ each t,j,s (N-mixture)
y[t,j,s] ~ dbin(pcap[j,s], N[t,j,s])
#Latent Number of Groups @ each t,j,s (negative binomial)
N[t,j,s] ~ dpois(lambda.star[t,j,s])
#Expected Number of Groups
lambda.star[t,j,s] <- rho[t,j,s] * lambda[t,j,s]
#Overdispersion parameter for Expected Number of Groups
rho[t,j,s] ~ dgamma(r.N, r.N)
#Linear predictor for Expected Number of Groups
lambda[t,j,s] <- exp(alpha0[s] + psi[j,s] + log(offset[j]))
}#end t loop distance sampling
}#end j loop distance sampling
#-----------------#
#-Transect counts-#
#-----------------#
for(j in (nsites[1] + 1):(nsites[1] + nsites[2])){
psi[j,s] ~ dnorm(0, tau_p[s])       #Transect effect parameter
#Scale parameter
sigma.new[j,s] <- exp(gamma0[s])
for(k in 1:8){
#Half normal detection function at midpt (length of rectangle)
g[k,j,s] <- exp(-mdpt[k]*mdpt[k]/(2*sigma.new[j,s]*sigma.new[j,s]))
#Detection probability for each distance class k (area of each rectangle)
f[k,j,s] <- g[k,j,s] * v/B
}#end k loop
#Detection probability at each transect (sum of rectangles)
pdet[j,s] <- sum(f[1:8,j,s])
for(t in nstart[j]:nend[j]){
#Observed population @ each t,j,s (Transect counts)
y[t,j,s] ~ dbin(pdet[j,s], N[t,j,s])
#Latent Number of Groups @ each t,j,s (negative binomial)
N[t,j,s] ~ dpois(lambda.star[t,j,s])
#Expected Number of Groups
lambda.star[t,j,s] <- rho[t,j,s] * lambda[t,j,s]
#Overdispersion parameter for Expected Number of Groups
rho[t,j,s] ~ dgamma(r.N, r.N)
#Linear predictor for Expected Number of Groups
lambda[t,j,s] <- exp(alpha0[s] + psi[j,s] + log(offset[j]))
}#end t loop transect counts
}#end j loop transect counts
}#end s loop
for(i in 1:nobs){
#Observed distance classes
dclass[i] ~ dcat(fc[1:nG, site[i], spec[i]])
}#end i loop
})
attach(Data)
constants <- list(nG = nG, v = v, B = B, mdpt = mdpt, nobs = nobs,
nstart = nstart, nend = nend, nsites = nsites, nspec = nspec,
site = site, spec = spec, offset = offset)
data <- list(y = y, dclass = dclass)
Nst <- y + 1
alpha0 <- function(){
alpha0 <- c(runif(1,2,3), runif(1,-0.5,0.5), runif(1,1.5,2.5), runif(1,1.5,2.5), runif(1,-1,0), runif(1,-0.5,0.5), runif(1,-0.5,0.5),
runif(1,2,3), runif(1,2,3), runif(1,3,4), runif(1,3,4), runif(1,-0.5,0.5), runif(1,2,3), runif(1,3,4))
return(alpha0)
}
inits <- function(){list(mu_s = runif(1, 5, 6), sig_s = runif(1, 0, 1),
gamma0 = runif(nspec, 4.75, 6),
mu_a0 = runif(1, 1, 2), tau_a0 = runif(1, 0, 1), alpha0 = alpha0(),
r.N = runif(1, 1, 2), tau_p = runif(nspec, 0, 10),
N = Nst)}
params <- c('mu_s', 'sig_s', 'gamma0',
'mu_a0', 'sig_a0', 'alpha0',
'r.N', 'tau_p')
model <- nimbleModel(model.code, constants = constants, data = data, inits = inits())
MCMCconf <- configureMCMC(model, monitors = params)
MCMC <- buildMCMC(MCMCconf)
model.comp <- compileNimble(model, MCMC)
model.comp <- compileNimble(model, MCMC)
install.packages("rtools")
install.packages("rtools")
R.version.string
install.packages("installr")
library(installr)
updateR()
R.version.string
R.version.string
library(coda)
library(tidyverse)
pattern <- "chain"
#files <- list.files(path = "./DataAnalysis", pattern = pattern, full.names = TRUE)
files <- list.files(path = "~/Blommel/DataAnalysis", pattern = pattern, full.names = TRUE)
nc <- length(files)
nc
files
setwd("Z:/Blommel")
pattern <- "chain"
files <- list.files(path = "./DataAnalysis", pattern = pattern, full.names = TRUE)
nc <- length(files)
nc
for(i in 1:nc){
load(files[i])
}
out <- mcmc.list(mget(paste0(pattern, 1:nc)))
params <- attr(out[[1]], "dimnames")[[2]]
Rhat <- gelman.diag(out[c(1:nc)][,params])
params
traceplot(out[c(1:nc)][,params[1:length(params)]])
for(i in 1:length(params)){
traceplot(out[c(1:nc)][,params[i]])
}
library(coda)
library(tidyverse)
pattern <- "chain"
#files <- list.files(path = "./DataAnalysis", pattern = pattern, full.names = TRUE)
files <- list.files(path = "~/Blommel/DataAnalysis", pattern = pattern, full.names = TRUE)
nc <- length(files)
nc
setwd("Z:/Blommel")
pattern <- "chain"
files <- list.files(path = "./DataAnalysis", pattern = pattern, full.names = TRUE)
nc <- length(files)
nc
for(i in 1:nc){
load(files[i])
}
out <- mcmc.list(mget(paste0(pattern, 1:nc)))
params <- attr(out[[1]], "dimnames")[[2]]
Rhat <- gelman.diag(out[c(1:nc)][,params])
params
Rhat <- gelman.diag(out[c(1:nc)][,params[1]])
Rhat
Rhat <- gelman.diag(out[c(1:nc)][,params[60]])
Rhat
for(i in 1:length(params)){
traceplot(out[c(1:nc)][,params[i]])
}
Rhat <- gelman.diag(out[c(1:nc)][,params[63]])
Rhat
length(params)
for(i in 1:length(params)){
traceplot(out[c(1:nc)][,params[i]])
Rhat <- gelman.diag(out[c(1:nc)][,params[i]])
Rhat
}
?rep()
Rhat_list <- rep(0,length(params))
Rhat_list
Rhat <- gelman.diag(out[c(1:nc)][,params[63]])
Rhat
Rhat[[1]][,1]
for(i in 1:length(params)){
traceplot(out[c(1:nc)][,params[i]])
Rhat <- gelman.diag(out[c(1:nc)][,params[i]])
Rhat_list[i] <- Rhat[[1]][,1]
}
Rhat_list
params
for(j in 1:length(Rhat_list)){
tmp <- as.numeric(which(Rhat_list[j] < 1.1))
print("Not converged")
print(params[tmp])
traceplot(out[c(1:nc)][,params[tmp]])
}
which(Rhat_list[j] < 1.1)
which(Rhat_list < 1.1)
traceplot(out[c(1:nc)][,params[45]])
params[45]
traceplot(out[c(1:nc)][,params[58]])
params[58]
conv <- which(Rhat_list < 1.1)
for(j in 1:length(conv)){
traceplot(out[c(1:nc)][,params[j]])
print(params[j])
}
library(coda)
library(tidyverse)
setwd("Z:/Blommel")
pattern <- "chain"
files <- list.files(path = "./DataAnalysis", pattern = pattern, full.names = TRUE)
nc <- length(files)
nc
getwd()
files <- list.files(path = "./DataAnalysis", pattern = pattern, full.names = TRUE)
files
